{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This repo contains experimentation in creating an operator catalog for OKD to replace the redhat catalog in OCP.","title":"Home"},{"location":"catalog-operators/","text":"Catalog Operators \u00b6 The RedHat catalog on OpenShift Container Platform contains over 90 operators. This experiment will concentrate on a small set of operators, primarily related to development activities: Operator Git repo Description DevWorkspace Operator https://github.com/devfile/devworkspace-operator Dependency for the Che workspaces operator Data Foundation https://github.com/red-hat-storage/odf-operator Storage operator to provide storage services, such as object storage Pipelines (Tekton) https://github.com/tektoncd/operator Tekton pipelines operator GitOps (ArgoCD) https://github.com/redhat-developer/gitops-operator ArgoCD operator Service Mesh (Istio) https://github.com/maistra/istio-operator Istio Service Mesh operator Serverless (Knative serving) https://github.com/openshift-knative/serverless-operator Serverless Knative serving operator Work to do for each operator \u00b6 For each of the operators in the table above we need to: Determine if pre-built containers are available in the public domain, or if we will need to build the containers Determine if the catalog data is available (operator bundles, channels and update details) in the repo or if we will need to create it Verify if pre-built containers are valid, or if they contain links to unavailable containers If we need to build any content, then what commands/tooling are needed. Will the operator pipeline be able to build it? Work to do to create an official OKD catalog \u00b6 Getting a catalog working is the first stage, but to create a catalog to be officially released for OKD requires additional work: is it possible to find out how OCP creates the RedHat catalog, is there anything we can reuse for the OKD catalog? is the config in public domain? can we validate we have the correct source repos identified? can we convert the Prow automation to the pipeline technology we choose to use? we need to create automation, driven off a GitHub repo to build the operators as required then update the catalog to include new operators should allow use on public cloud or in private environments, on and off OKD (e.g. minikube) to allow customization of the OKD catalog, or the catalog to be used as a basis for custom catalogs should we use pre-built containers, or is this unsafe and would be better for us to build all the containers from source? is there any reason to possible rebase the containers on UBI/Fedora/CentOS Stream base images? what is the governance we need to put in place to control the catalog? what testing / validation do we need to have in place to validate operators/catalog before release? what naming convention are we going to use? if we use different names from the RedHat catalog, then we break reuse of automation (Ansible / Terraform) between OKD and OCP are there any legal limitations regarding use of RedHat/OpenShift names within the catalog? what needs to be in place to support different versions of OKD? we shouldn't back port to previous versions of OKD an install of a previous version of OKD should work (we shouldn't try to install the newest catalog of operators, but the catalog appropriate for the OKD versions we should start with 4.12 - not plan to support previous versions?","title":"Catalog Operators"},{"location":"catalog-operators/#catalog-operators","text":"The RedHat catalog on OpenShift Container Platform contains over 90 operators. This experiment will concentrate on a small set of operators, primarily related to development activities: Operator Git repo Description DevWorkspace Operator https://github.com/devfile/devworkspace-operator Dependency for the Che workspaces operator Data Foundation https://github.com/red-hat-storage/odf-operator Storage operator to provide storage services, such as object storage Pipelines (Tekton) https://github.com/tektoncd/operator Tekton pipelines operator GitOps (ArgoCD) https://github.com/redhat-developer/gitops-operator ArgoCD operator Service Mesh (Istio) https://github.com/maistra/istio-operator Istio Service Mesh operator Serverless (Knative serving) https://github.com/openshift-knative/serverless-operator Serverless Knative serving operator","title":"Catalog Operators"},{"location":"catalog-operators/#work-to-do-for-each-operator","text":"For each of the operators in the table above we need to: Determine if pre-built containers are available in the public domain, or if we will need to build the containers Determine if the catalog data is available (operator bundles, channels and update details) in the repo or if we will need to create it Verify if pre-built containers are valid, or if they contain links to unavailable containers If we need to build any content, then what commands/tooling are needed. Will the operator pipeline be able to build it?","title":"Work to do for each operator"},{"location":"catalog-operators/#work-to-do-to-create-an-official-okd-catalog","text":"Getting a catalog working is the first stage, but to create a catalog to be officially released for OKD requires additional work: is it possible to find out how OCP creates the RedHat catalog, is there anything we can reuse for the OKD catalog? is the config in public domain? can we validate we have the correct source repos identified? can we convert the Prow automation to the pipeline technology we choose to use? we need to create automation, driven off a GitHub repo to build the operators as required then update the catalog to include new operators should allow use on public cloud or in private environments, on and off OKD (e.g. minikube) to allow customization of the OKD catalog, or the catalog to be used as a basis for custom catalogs should we use pre-built containers, or is this unsafe and would be better for us to build all the containers from source? is there any reason to possible rebase the containers on UBI/Fedora/CentOS Stream base images? what is the governance we need to put in place to control the catalog? what testing / validation do we need to have in place to validate operators/catalog before release? what naming convention are we going to use? if we use different names from the RedHat catalog, then we break reuse of automation (Ansible / Terraform) between OKD and OCP are there any legal limitations regarding use of RedHat/OpenShift names within the catalog? what needs to be in place to support different versions of OKD? we shouldn't back port to previous versions of OKD an install of a previous version of OKD should work (we shouldn't try to install the newest catalog of operators, but the catalog appropriate for the OKD versions we should start with 4.12 - not plan to support previous versions?","title":"Work to do to create an official OKD catalog"},{"location":"catalog/","text":"Create Catalog \u00b6 It is easy to create a new catalog using instructions found in the Operator Lifecycle Manager documentation . You also need to have the operator development tooling installed. Todo Windows commands, or assume Linux Subsystem for Windows can be used? create a directory for the operator catalog mkdir okd-catalog generate the container file opm generate dockerfile okd-catalog Add operators \u00b6 Once the catalog structure is created and the container file has been created you can add operators to the catalog. Operators are added by creating a directory in the okd-catalog director and adding details of the operator bundle. This information can be added using File Based Catalog (FCB) or the new Veneers to define the operators. Veneers are currently in alpha and subject to change, but provide a simplification over FCB. Details of how to add operators will be covered in more detail in subsequent pages Building the catalog \u00b6 Before building a catalog you should validate the catalog definitions: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest Adding the catalog to an OKD cluster \u00b6 Warning This repo and the operator catalog created should be considered as experimental and work in progress so should not be installed on an important cluster You can add the catalog to an OKD cluster using the admin console or command line to set a new CatalogSource CRD: apiVersion : operators.coreos.com/v1alpha1 kind : CatalogSource metadata : name : okd-catalog namespace : openshift-marketplace spec : displayName : OKD Catalog image : quay.io/brianinnesuk/okd-catalog publisher : OKD Community sourceType : grpc updateStrategy : registryPoll : interval : 10m0s","title":"Catalog"},{"location":"catalog/#create-catalog","text":"It is easy to create a new catalog using instructions found in the Operator Lifecycle Manager documentation . You also need to have the operator development tooling installed. Todo Windows commands, or assume Linux Subsystem for Windows can be used? create a directory for the operator catalog mkdir okd-catalog generate the container file opm generate dockerfile okd-catalog","title":"Create Catalog"},{"location":"catalog/#add-operators","text":"Once the catalog structure is created and the container file has been created you can add operators to the catalog. Operators are added by creating a directory in the okd-catalog director and adding details of the operator bundle. This information can be added using File Based Catalog (FCB) or the new Veneers to define the operators. Veneers are currently in alpha and subject to change, but provide a simplification over FCB. Details of how to add operators will be covered in more detail in subsequent pages","title":"Add operators"},{"location":"catalog/#building-the-catalog","text":"Before building a catalog you should validate the catalog definitions: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest","title":"Building the catalog"},{"location":"catalog/#adding-the-catalog-to-an-okd-cluster","text":"Warning This repo and the operator catalog created should be considered as experimental and work in progress so should not be installed on an important cluster You can add the catalog to an OKD cluster using the admin console or command line to set a new CatalogSource CRD: apiVersion : operators.coreos.com/v1alpha1 kind : CatalogSource metadata : name : okd-catalog namespace : openshift-marketplace spec : displayName : OKD Catalog image : quay.io/brianinnesuk/okd-catalog publisher : OKD Community sourceType : grpc updateStrategy : registryPoll : interval : 10m0s","title":"Adding the catalog to an OKD cluster"},{"location":"operators/data-foundation/","text":"Data Foundation \u00b6 Git Repository : https://github.com/red-hat-storage/odf-operator This operator repo contains the data OPM data in the catalog folder. This operator publishes containers to quay.io , so it looks like no containers need to be built to use this on OKD - this turns out not to be the case! Copying the bundle.yaml and index.yaml files from the catalog directory of odf-operator repository into the okd-catalog/odf-operator directory will add the operator to the catalog. Verify the catalog is valid by running the following command in the root directory of the project: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest Operator imports container images from protected registry \u00b6 The operator appears in the catalog and can be selected to be installed on an OKD cluster, however, the install will not complete as the operator tries to pulls the ose-kube-rbac-proxy image from the RedHat registry which is protected by a pull secret. This suggests that we will need to build the operator containers using an alternate kube-rbac-proxy image Kube RBAC Proxy \u00b6 A Kube RBAC Proxy is needed by many operators. There are a number of containers available: registry.redhat.io/openshift4/ose-kube-rbac-proxy gcr.io/kubebuilder/kube-rbac-proxy The OpenShift version seems to be sourced in repo https://github.com/openshift-auth/kube-rbac-proxy-downstream or https://github.com/openshift/kube-rbac-proxy . Todo Determine which is correct git repo and see if there are any built containers in a public repo. If not we need to decide if the google implementation can be used or if we need to build the containers","title":"Data Foundation"},{"location":"operators/data-foundation/#data-foundation","text":"Git Repository : https://github.com/red-hat-storage/odf-operator This operator repo contains the data OPM data in the catalog folder. This operator publishes containers to quay.io , so it looks like no containers need to be built to use this on OKD - this turns out not to be the case! Copying the bundle.yaml and index.yaml files from the catalog directory of odf-operator repository into the okd-catalog/odf-operator directory will add the operator to the catalog. Verify the catalog is valid by running the following command in the root directory of the project: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest","title":"Data Foundation"},{"location":"operators/data-foundation/#operator-imports-container-images-from-protected-registry","text":"The operator appears in the catalog and can be selected to be installed on an OKD cluster, however, the install will not complete as the operator tries to pulls the ose-kube-rbac-proxy image from the RedHat registry which is protected by a pull secret. This suggests that we will need to build the operator containers using an alternate kube-rbac-proxy image","title":"Operator imports container images from protected registry"},{"location":"operators/data-foundation/#kube-rbac-proxy","text":"A Kube RBAC Proxy is needed by many operators. There are a number of containers available: registry.redhat.io/openshift4/ose-kube-rbac-proxy gcr.io/kubebuilder/kube-rbac-proxy The OpenShift version seems to be sourced in repo https://github.com/openshift-auth/kube-rbac-proxy-downstream or https://github.com/openshift/kube-rbac-proxy . Todo Determine which is correct git repo and see if there are any built containers in a public repo. If not we need to decide if the google implementation can be used or if we need to build the containers","title":"Kube RBAC Proxy"},{"location":"operators/devworkspace/","text":"DevWorkspace \u00b6 Git repository : https://github.com/devfile/devworkspace-operator This operator repo contains the data OPM data in the olm-catalog folder. However, there is an issue with the data which is discussed below. This operator publishes containers to quay.io , so no containers need to be built to use this on OKD Catalog data \u00b6 The repo contains the data for the Operator Lifecycle Manager, but in the required repository section it lists the kube_rbac_proxy being located at registry.redhat.io/openshift4/ose-kube-rbac-proxy:v4.8 , which requires an access token to access the RedHat registry. I think this is an error, as the operator uses the Google image located at gcr.io/kubebuilder/kube-rbac-proxy:v0.13.1 To add the operator to the catalog, the opportunity to explore the new veneer feature was chosen. The veneer is defined in file okd-catalog/devworkspace-operator/devworkspace-operator-veneer.yaml : Schema : olm.semver GenerateMajorChannels : true GenerateMinorChannels : false fast : Bundles : - Image : quay.io/devfile/devworkspace-operator-bundle:v0.19.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.18.1 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.18.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.17.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.16.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.15.3 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.15.2 This veneer can be converted into the catalog.yaml file needed by the Operator Lifecycle Manager using the following command in the devworkspace-operator folder: opm alpha render-veneer semver -o yaml devworkspace-operator-veneer.yaml > catalog.yaml Verify the catalog is valid by running the following command in the root directory of the project: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest","title":"DevWorkspace"},{"location":"operators/devworkspace/#devworkspace","text":"Git repository : https://github.com/devfile/devworkspace-operator This operator repo contains the data OPM data in the olm-catalog folder. However, there is an issue with the data which is discussed below. This operator publishes containers to quay.io , so no containers need to be built to use this on OKD","title":"DevWorkspace"},{"location":"operators/devworkspace/#catalog-data","text":"The repo contains the data for the Operator Lifecycle Manager, but in the required repository section it lists the kube_rbac_proxy being located at registry.redhat.io/openshift4/ose-kube-rbac-proxy:v4.8 , which requires an access token to access the RedHat registry. I think this is an error, as the operator uses the Google image located at gcr.io/kubebuilder/kube-rbac-proxy:v0.13.1 To add the operator to the catalog, the opportunity to explore the new veneer feature was chosen. The veneer is defined in file okd-catalog/devworkspace-operator/devworkspace-operator-veneer.yaml : Schema : olm.semver GenerateMajorChannels : true GenerateMinorChannels : false fast : Bundles : - Image : quay.io/devfile/devworkspace-operator-bundle:v0.19.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.18.1 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.18.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.17.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.16.0 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.15.3 - Image : quay.io/devfile/devworkspace-operator-bundle:v0.15.2 This veneer can be converted into the catalog.yaml file needed by the Operator Lifecycle Manager using the following command in the devworkspace-operator folder: opm alpha render-veneer semver -o yaml devworkspace-operator-veneer.yaml > catalog.yaml Verify the catalog is valid by running the following command in the root directory of the project: opm validate okd-catalog once the validation passes you can build the catalog images: podman build . -f okd-catalog.Dockerfile -t quay.io/brianinnesuk/okd-catalog:latest podman push quay.io/brianinnesuk/okd-catalog:latest","title":"Catalog data"},{"location":"operators/gitops/","text":"GitOps \u00b6 Todo This needs to be investigated","title":"GitOps"},{"location":"operators/gitops/#gitops","text":"Todo This needs to be investigated","title":"GitOps"},{"location":"operators/pipelines/","text":"Pipelines \u00b6 Todo This needs to be investigated","title":"Pipelines"},{"location":"operators/pipelines/#pipelines","text":"Todo This needs to be investigated","title":"Pipelines"},{"location":"operators/serverless/","text":"Serverless \u00b6 Todo This needs to be investigated","title":"Serverless"},{"location":"operators/serverless/#serverless","text":"Todo This needs to be investigated","title":"Serverless"},{"location":"operators/service-mesh/","text":"Service Mesh \u00b6 Todo This needs to be investigated","title":"Service Mesh"},{"location":"operators/service-mesh/#service-mesh","text":"Todo This needs to be investigated","title":"Service Mesh"}]}